{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/giakhang/dev/RDPN6D\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/giakhang/miniconda3/envs/rdpn6d/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "\u001b[32m[04/08 17:47:25 detectron2]: \u001b[0mCommand line arguments: Namespace(format='onnx', export_method='tracing', config_file='./configs/gdrn/a6_cPnP.py', run_eval=False, output='./', opts=[])\n",
      "[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 1) (function operator())\n",
      "\u001b[33m[0408_174727@core/gdrn_modeling/datasets/lumi_piano.py:357]\u001b[0m \u001b[5m\u001b[33mDBG \u001b[0mregister dataset: lumi_piano_train\n",
      "\u001b[33m[0408_174727@core/gdrn_modeling/datasets/lumi_piano.py:357]\u001b[0m \u001b[5m\u001b[33mDBG \u001b[0mregister dataset: lumi_piano_test\n",
      "\u001b[33m[0408_174727@core/gdrn_modeling/datasets/syn_lumi_piano.py:343]\u001b[0m \u001b[5m\u001b[33mDBG \u001b[0mregister dataset: syn_lumi_piano_train\n",
      "\u001b[32m[04/08 17:47:28 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output/gdrn/lumi_piano/2025_03_11_01/model_0145349.pth ...\n",
      "\u001b[32m[04/08 17:47:28 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "| lumi_piano | 130          |\n",
      "|            |              |\u001b[0m\n",
      "/home/giakhang/dev/RDPN6D/core/gdrn_modeling/models/GDRN.py:521: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if coor_x.shape[1] > 1 and coor_y.shape[1] > 1 and coor_z.shape[1] > 1:\n",
      "/home/giakhang/dev/RDPN6D/core/gdrn_modeling/models/model_utils.py:30: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert c == 1, c\n",
      "/home/giakhang/dev/RDPN6D/core/gdrn_modeling/models/conv_pnp_net.py:138: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if in_c == 3 or in_c == 5 or in_c == 6 or in_c == 8:\n",
      "/home/giakhang/dev/RDPN6D/core/gdrn_modeling/models/pose_from_pred_centroid_z.py:110: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pred_rots.shape[-1] == 4 and pred_rots.ndim == 2:\n",
      "/home/giakhang/dev/RDPN6D/core/utils/utils.py:212: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  cam_ray = torch.tensor([0, 0, 1.0], dtype=translation.dtype, device=translation.device)  # (3,)\n",
      "/home/giakhang/dev/RDPN6D/core/utils/pose_utils.py:331: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert quat.ndim == 2 and quat.shape[1] == 4, quat.shape\n",
      "\u001b[32m[04/08 17:47:31 detectron2]: \u001b[0mInputs schema: TupleSchema(schemas=[ListSchema(schemas=[DictSchema(schemas=[IdentitySchema(), IdentitySchema(), IdentitySchema(), IdentitySchema(), IdentitySchema(), IdentitySchema(), IdentitySchema(), IdentitySchema(), IdentitySchema()], sizes=[1, 1, 1, 1, 1, 1, 1, 1, 1], keys=dict_keys(['roi_img', 'roi_cls', 'roi_cam', 'roi_wh', 'roi_center', 'resize_ratio', 'roi_coord_2d', 'roi_extent', 'fps']))], sizes=[9])], sizes=[9])\n",
      "\u001b[32m[04/08 17:47:31 detectron2]: \u001b[0mOutputs schema: DictSchema(schemas=[IdentitySchema(), IdentitySchema()], sizes=[1, 1], keys=dict_keys(['rot', 'trans']))\n",
      "\u001b[32m[04/08 17:47:31 detectron2]: \u001b[0mSuccess.\n"
     ]
    }
   ],
   "source": [
    "!python3 export_model.py \\\n",
    "    --config-file ./configs/gdrn/a6_cPnP.py \\\n",
    "    --export-method tracing \\\n",
    "    --format onnx \\\n",
    "    --output ./ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#netron ./model.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/01/2025-19:39:20] [TRT] [I] [MemUsageChange] Init CUDA: CPU +18, GPU +0, now: CPU 120, GPU 215 (MiB)\n",
      "[04/01/2025-19:39:26] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1458, GPU +266, now: CPU 1655, GPU 481 (MiB)\n",
      "/home/giakhang/dev/TensorRT-8.6.1.6/samples/python/detectron2/build_engine.py:134: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  self.config.max_workspace_size = workspace * (2 ** 30)\n",
      "[04/01/2025-19:39:26] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[04/01/2025-19:39:26] [TRT] [W] onnx2trt_utils.cpp:400: One or more weights outside the range of INT32 was clamped\n",
      "[04/01/2025-19:39:26] [TRT] [W] Tensor DataType is determined at build time for tensors not marked as input or output.\n",
      "INFO:EngineBuilder:Network Description\n",
      "INFO:EngineBuilder:Input 'onnx::Slice_0' with shape (1, 6, 256, 256) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Input 'roi_cams' with shape (1, 3, 3) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Input 'roi_whs' with shape (1, 2) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Input 'roi_centers' with shape (1, 2) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Input 'onnx::Concat_6' with shape (1, 5, 64, 64) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Input 'onnx::Unsqueeze_8' with shape (1, 32, 3) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Output '979' with shape (1, 3, 3) and dtype DataType.FLOAT\n",
      "INFO:EngineBuilder:Output 'translation' with shape (1, 3) and dtype DataType.FLOAT\n",
      "/home/giakhang/dev/TensorRT-8.6.1.6/samples/python/detectron2/build_engine.py:167: DeprecationWarning: Use network created with NetworkDefinitionCreationFlag::EXPLICIT_BATCH flag instead.\n",
      "  self.builder.max_batch_size = self.batch_size\n",
      "INFO:EngineBuilder:Building fp16 Engine in /home/giakhang/dev/RDPN6D/engine.trt\n",
      "[04/01/2025-19:39:27] [TRT] [I] Graph optimization time: 0.641566 seconds.\n",
      "[04/01/2025-19:39:27] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +6, GPU +8, now: CPU 1821, GPU 553 (MiB)\n",
      "[04/01/2025-19:39:27] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 1821, GPU 563 (MiB)\n",
      "[04/01/2025-19:39:27] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[04/01/2025-19:41:16] [TRT] [I] Detected 8 inputs and 2 output network tensors.\n",
      "[04/01/2025-19:41:17] [TRT] [I] Total Host Persistent Memory: 298896\n",
      "[04/01/2025-19:41:17] [TRT] [I] Total Device Persistent Memory: 18432\n",
      "[04/01/2025-19:41:17] [TRT] [I] Total Scratch Memory: 1097728\n",
      "[04/01/2025-19:41:17] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 89 MiB, GPU 192 MiB\n",
      "[04/01/2025-19:41:17] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 98 steps to complete.\n",
      "[04/01/2025-19:41:17] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 1.89431ms to assign 6 blocks to 98 nodes requiring 4807680 bytes.\n",
      "[04/01/2025-19:41:17] [TRT] [I] Total Activation Memory: 4807168\n",
      "[04/01/2025-19:41:17] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2094, GPU 689 (MiB)\n",
      "[04/01/2025-19:41:17] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +8, now: CPU 2095, GPU 697 (MiB)\n",
      "[04/01/2025-19:41:17] [TRT] [W] TensorRT encountered issues when converting weights between types and that could affect accuracy.\n",
      "[04/01/2025-19:41:17] [TRT] [W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\n",
      "[04/01/2025-19:41:17] [TRT] [W] Check verbose logs for the list of affected weights.\n",
      "[04/01/2025-19:41:17] [TRT] [W] - 60 weights are affected by this issue: Detected subnormal FP16 values.\n",
      "[04/01/2025-19:41:17] [TRT] [W] - 35 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\n",
      "[04/01/2025-19:41:17] [TRT] [W] - 2 weights are affected by this issue: Detected finite FP32 values which would overflow in FP16 and converted them to the closest finite FP16 value.\n",
      "[04/01/2025-19:41:17] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +65, GPU +70, now: CPU 65, GPU 70 (MiB)\n",
      "INFO:EngineBuilder:Serializing engine to file: /home/giakhang/dev/RDPN6D/engine.trt\n"
     ]
    }
   ],
   "source": [
    "!python3 tensorrt/build_engine.py \\\n",
    "    --onnx ./model.onnx \\\n",
    "    --engine ./engine.trt \\\n",
    "    --precision fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdpn6d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
